{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4X7qahzMX05u"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXoBaXRDKuMV"
      },
      "source": [
        "#Next Frame Prediction using Pix2PixHD\n",
        "\n",
        "Notbook adapted from Derrick Schultz's Next Frame Prediction using Pix2PixHD which is Forked repo and tutorial based on [JC Testud’s excellent repo and Medium](https://medium.com/@jctestud/video-generation-with-pix2pix-aed5b1b69f57) article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfOexYWJX3Pt"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K--AsrIzpH58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b9ac77-b0b5-41e9-9daa-e766330d375b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUvLbCJtLqaV"
      },
      "source": [
        "## Install libraries and dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQbRsmWdvjUo"
      },
      "source": [
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/nfp-colab/pix2pixHD/\"):\n",
        "    %cd /content/drive/MyDrive/nfp-colab/pix2pixHD/\n",
        "    # !git pull\n",
        "    !pip install dominate\n",
        "else:\n",
        "    %cd /content/drive/MyDrive\n",
        "    !mkdir nfp-colab\n",
        "    %cd nfp-colab\n",
        "    !git clone -b video https://github.com/dvschultz/pix2pixHD.git\n",
        "    !pip install dominate\n",
        "    %cd pix2pixHD/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "process video using ffmpeg"
      ],
      "metadata": {
        "id": "WMYPw0tRL3bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scale video\n",
        "!ffmpeg -i /content/drive/MyDrive/dmlap-final/stylegan/stylegan3/trypophobia0-7.mp4 -vf \"scale=1280:736\" /content/drive/MyDrive/dmlap-final/Vids/source/trypophobia0-7resized.mp4.mp4"
      ],
      "metadata": {
        "id": "kQhSSp6zL1_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trim video to 30s\n",
        "!ffmpeg -i /content/drive/MyDrive/dmlap-final/Vids/source/trypophobia0-7resized.mp4.mp4 -t 30 /content/drive/MyDrive/dmlap-final/Vids/source/trypophobia_30s.mp4"
      ],
      "metadata": {
        "id": "j16Co57uiKnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract frames\n",
        "!ffmpeg -ss 00:00:00 -i \"/content/sample2.mp4\" -vf \"fps=24\" \"/content/drive/MyDrive/nfp-colab/pix2pixHD/datasets/londonBridge_trim6/test_frames/frame_%06d.png\""
      ],
      "metadata": {
        "id": "au2LDl_FZZpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzLGf05WXMFV"
      },
      "source": [
        "## Extract frames from video\n",
        "\n",
        "Upload a video to either Colab or Google Drive.\n",
        "\n",
        "* `-video` is the path to the video file\n",
        "* `-name` should be a unique project name\n",
        "* `-width` and `-height` **must** to be a multiple of 32\n",
        "* `-p2pdir` leave as `.`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWRL2ty6N9LD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2483aa5-a2a7-48e4-c7bf-74b41600d5eb"
      },
      "source": [
        "!python extract_frames.py -video /content/drive/MyDrive/dmlap-final/Vids/source/trypophobia_30s.mp4 -name trypophobia -p2pdir . -width 1280 -height 736"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating the dataset structure\n",
            "ffmpeg -v 16 -i /content/drive/MyDrive/dmlap-final/Vids/source/trypophobia_30s.mp4 -q:v 2 -vf \"scale=iw*736/ih:736, crop=1280:736\" /content/drive/MyDrive/nfp-colab/pix2pixHD/datasets/trypophobia/train_frames/frame-%06d.jpg -hide_banner\n",
            "extracting the frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL9BZkBA_QRR"
      },
      "source": [
        "## Train your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X7qahzMX05u"
      },
      "source": [
        "### Initial training\n",
        "\n",
        "Note: if you have a large dataset, this may timeout initially (`ValueError: __len__() should return >= 0`). Give it a minute or two and run it again.\n",
        "\n",
        "*   `--name` should be a unique name (think of it like a project name). For your sanity I recommend using the same `-name` as above.\n",
        "*   `--dataroot` should point to your dataset. This will usually be in `./datasets/[your project name]`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with schedule sampling\n",
        "!python train_video.py --name water_project --dataroot ./datasets/water_dataset/ --save_epoch_freq 1 --ngf 64 --scheduled_sampling --serial_batches"
      ],
      "metadata": {
        "id": "CpJLa1_UHtTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzHBGVnUKEzE"
      },
      "source": [
        "!python train_video.py --name fire_noss --dataroot ./datasets/fire/ --save_epoch_freq 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "trying to fix this error appears to be a version hell issue:\n",
        "\n",
        "\n",
        "```\n",
        "Traceback (most recent call last):\n",
        "  File \"/content/drive/MyDrive/nfp-colab/pix2pixHD/train_video.py\", line 55, in <module>\n",
        "    opt.print_freq = lcm(opt.print_freq, opt.batchSize)\n",
        "  File \"/content/drive/MyDrive/nfp-colab/pix2pixHD/train_video.py\", line 11, in lcm\n",
        "    def lcm(a,b): return abs(a * b)/fractions.gcd(a,b) if a and b else 0\n",
        "AttributeError: module 'fractions' has no attribute 'gcd'\n",
        "```\n",
        "\n",
        "will this be a fix?\n",
        "https://stackoverflow.com/questions/66174862/import-error-cant-import-name-gcd-from-fractions\n",
        "\n",
        "(fixed by changing this in train_video.py\n",
        "\n",
        "\n",
        "```\n",
        "def lcm(a,b): return abs(a * b)/fractions.gcd(a,b) if a and b else 0\n",
        "```\n",
        "\n",
        "to\n",
        "\n",
        "```\n",
        "import math\n",
        "def lcm(a,b): return abs(a * b)/math.gcd(a,b) if a and b else 0\n",
        "```\n",
        "\n",
        "now the training runs no problem!"
      ],
      "metadata": {
        "id": "2y2_wYJSPP2r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GDg3CeW_1TD"
      },
      "source": [
        "### Continue Training\n",
        "To pick up from a previous training session run the same command you ran to start with and append `--continue_train` to the end of the command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5q3dE9S_5eg"
      },
      "source": [
        "!python train_video.py --name londonBridge_ss --dataroot ./datasets/londonBridge_480/ --save_epoch_freq 2 --continue_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jly_3OyBoGg2"
      },
      "source": [
        "#Generating Videos\n",
        "\n",
        "There are a number of additional arguments you’ll need to include in this command:\n",
        "\n",
        "*   `--fps` frame rate for your video\n",
        "*   `--how_many` how many frames you want to create (this + fps = video length)\n",
        "*   `--which_epoch` which epoch you want to generate videos from (note: if you choose `133` but there’s no epoch 133 model file, this will throw an error)\n",
        "*   `--start_from` by default your video will start predicting images from the 60th frame of your training set. You can pass in the path to a different frame to have it start from that frame\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_video.py --name londonBridge_ss --dataroot ./datasets/firetrim2/ --fps 24 --how_many 800 --which_epoch latest --resize_or_crop none"
      ],
      "metadata": {
        "id": "xZzljLtSLHs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_progress_video.py --name fire_noss --dataroot ./datasets/fire/ --fps 24 --ngf 64 --pstart 1 --pstop 40"
      ],
      "metadata": {
        "id": "bbMCpmXV2YQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reverse video\n",
        "!ffmpeg -i /content/12s.mp4 -vf reverse /content/12s-reversed.mp4"
      ],
      "metadata": {
        "id": "a0iId09rO0FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert format\n",
        "!ffmpeg -i \"/content/drive/MyDrive/nfp-colab/pix2pixHD/hand.MOV\" -c:v libx264 -c:a aac \"/content/drive/MyDrive/nfp-colab/pix2pixHD/hand.mp4\""
      ],
      "metadata": {
        "id": "L_0KV9Wtoebv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge audio to video\n",
        "!ffmpeg -i stitchedfin.mp4 -i londonBridge.mp4 -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 hand-audio2.mp4"
      ],
      "metadata": {
        "id": "cLVI4R8KmipP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}